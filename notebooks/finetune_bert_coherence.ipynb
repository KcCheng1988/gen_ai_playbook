{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Reward Model as Coherence Level Classifier\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add coherence scores\n",
    "___\n",
    "* 0 = Least coherent\n",
    "* 1 = Moderately coherent\n",
    "* 2 = Mostly coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How is your day so far?</td>\n",
       "      <td>How is your day so far? \" \\n = = Background = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The greatest strength of AI nowadays is</td>\n",
       "      <td>The greatest strength of AI nowadays is the us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I bought a ticket to Paris</td>\n",
       "      <td>I bought a ticket to Paris to take part in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is so much fun in having a roller coaste...</td>\n",
       "      <td>There is so much fun in having a roller coaste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every time I go the restaurant, the place is</td>\n",
       "      <td>Every time I go the restaurant, the place is v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0                            How is your day so far?   \n",
       "1            The greatest strength of AI nowadays is   \n",
       "2                         I bought a ticket to Paris   \n",
       "3  There is so much fun in having a roller coaste...   \n",
       "4       Every time I go the restaurant, the place is   \n",
       "\n",
       "                                            response  \n",
       "0  How is your day so far? \" \\n = = Background = ...  \n",
       "1  The greatest strength of AI nowadays is the us...  \n",
       "2  I bought a ticket to Paris to take part in the...  \n",
       "3  There is so much fun in having a roller coaste...  \n",
       "4  Every time I go the restaurant, the place is v...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/gpt2_sample_responses.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the dataframe, and gather human response\n",
    "scores = []\n",
    "for i, j in df.iterrows():\n",
    "    cmd_lines = f\"prompt: {j['prompt']}\\n\\nresponse:{j['response']}\"\n",
    "    score = input(cmd_lines)\n",
    "    scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How is your day so far?</td>\n",
       "      <td>How is your day so far? \" \\n = = Background = ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The greatest strength of AI nowadays is</td>\n",
       "      <td>The greatest strength of AI nowadays is the us...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I bought a ticket to Paris</td>\n",
       "      <td>I bought a ticket to Paris to take part in the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is so much fun in having a roller coaste...</td>\n",
       "      <td>There is so much fun in having a roller coaste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every time I go the restaurant, the place is</td>\n",
       "      <td>Every time I go the restaurant, the place is v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0                            How is your day so far?   \n",
       "1            The greatest strength of AI nowadays is   \n",
       "2                         I bought a ticket to Paris   \n",
       "3  There is so much fun in having a roller coaste...   \n",
       "4       Every time I go the restaurant, the place is   \n",
       "\n",
       "                                            response  score  \n",
       "0  How is your day so far? \" \\n = = Background = ...      0  \n",
       "1  The greatest strength of AI nowadays is the us...      2  \n",
       "2  I bought a ticket to Paris to take part in the...      2  \n",
       "3  There is so much fun in having a roller coaste...      1  \n",
       "4  Every time I go the restaurant, the place is v...      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type-cast scores to integers\n",
    "scores = [int(score) for score in scores]\n",
    "\n",
    "df['score'] = scores\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scores together with the prompt and response\n",
    "df.to_csv('../datasets/gpt2_sample_response.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess dataset\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/kccheng1988/.cache/huggingface/datasets/csv/gpt2_sample_response-675f075b2650ebe9/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c95d957dfc42cfa2b43cb64a3208e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'response', 'score'],\n",
       "        num_rows: 26\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load datasets from CSV\n",
    "dataset = load_dataset(path=\"csv\", name=\"gpt2_sample_response\", data_dir = '../datasets', data_files = 'gpt2_sample_response.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'How is your day so far?',\n",
       " 'response': 'How is your day so far? \" \\n = = Background = = \\n On April 19, 2009, a visit to the City of New York City came as a shock to',\n",
       " 'score': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input length:  512\n"
     ]
    }
   ],
   "source": [
    "## Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "max_input_length = tokenizer.max_model_input_sizes['distilbert-base-cased']\n",
    "print('Max input length: ', max_input_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/kccheng1988/.cache/huggingface/datasets/csv/gpt2_sample_response-675f075b2650ebe9/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-11b2cf245df8d875.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c983bc055324e07adfd2c413bfa075e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Define preprocessing steps \n",
    "\n",
    "# 1. Concatenate prompt and response into a single text column\n",
    "def concatenate_prompt_response(sample):\n",
    "    return {'text' : f\"Prompt: {sample['prompt']} \\n\\n Response: {sample['response']}\"}\n",
    "\n",
    "# 2. Tokenize concatenated text\n",
    "def tokenize_text(sample):\n",
    "    output = tokenizer(\n",
    "        sample['text'],\n",
    "        truncation = True,\n",
    "        max_length = max_input_length\n",
    "    )\n",
    "\n",
    "    return output\n",
    "\n",
    "dataset_proc = dataset.map(concatenate_prompt_response)\n",
    "dataset_proc = dataset_proc.map(tokenize_text)\n",
    "dataset_proc = dataset_proc.remove_columns(['prompt', 'response'])\n",
    "dataset_proc = dataset_proc.rename_columns({'score': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 26\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_proc['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up data collator that could handle automated batch padding\n",
    "data_collator  = DataCollatorWithPadding(tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Set up mapping betwee binary label and coherence label\n",
    "id2label = {0 : \"least\", 1 : \"medium\", 2 : \"mostly\"}\n",
    "label2id = {\"least\" : 0, \"medium\" : 1, \"mostly\" : 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## 2. Set up DistilBert model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels = 3,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Set up training arguments\n",
    "# Requires accelerate>=0.20.1\n",
    "# !pip install accelerate -U\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"../models/coherence-classifier\",\n",
    "    do_eval = False,\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = 2,\n",
    "    num_train_epochs = 5,\n",
    "    weight_decay = 0.01,\n",
    "    save_strategy = 'epoch',\n",
    "    push_to_hub = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Set up evaluation metrics\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    accuracy = evaluate.load('accuracy')\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "    return accuracy.compute(predictions = predictions, references = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Set up trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset_proc['train'],\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kccheng1988/anaconda3/envs/ds/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Changing param values is not allowed. Param with key='logging_dir' was already logged with value='tmp_trainer/runs/Jul27_09-58-44_kccheng1988' for run ID='49e94028fb2144d181a78ca9e06c5ce5'. Attempted logging new value 'tmp_trainer/runs/Jul27_10-02-10_kccheng1988'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:1045\u001b[0m, in \u001b[0;36mFileStore.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m params:\n\u001b[0;32m-> 1045\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_run_param(run_info, param)\n\u001b[1;32m   1046\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metrics:\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:950\u001b[0m, in \u001b[0;36mFileStore._log_run_param\u001b[0;34m(self, run_info, param)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(param_path):\n\u001b[0;32m--> 950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_new_param_value(\n\u001b[1;32m    951\u001b[0m         param_path\u001b[39m=\u001b[39;49mparam_path,\n\u001b[1;32m    952\u001b[0m         param_key\u001b[39m=\u001b[39;49mparam\u001b[39m.\u001b[39;49mkey,\n\u001b[1;32m    953\u001b[0m         run_id\u001b[39m=\u001b[39;49mrun_info\u001b[39m.\u001b[39;49mrun_id,\n\u001b[1;32m    954\u001b[0m         new_value\u001b[39m=\u001b[39;49mwriteable_param_value,\n\u001b[1;32m    955\u001b[0m     )\n\u001b[1;32m    956\u001b[0m make_containing_dirs(param_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:970\u001b[0m, in \u001b[0;36mFileStore._validate_new_param_value\u001b[0;34m(self, param_path, param_key, run_id, new_value)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[39mif\u001b[39;00m current_value \u001b[39m!=\u001b[39m new_value:\n\u001b[0;32m--> 970\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    971\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mChanging param values is not allowed. Param with key=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparam_key\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was already\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    972\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m logged with value=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcurrent_value\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for run ID=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrun_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Attempted logging\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    973\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m new value \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnew_value\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    974\u001b[0m         databricks_pb2\u001b[39m.\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    975\u001b[0m     )\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='logging_dir' was already logged with value='tmp_trainer/runs/Jul27_09-58-44_kccheng1988' for run ID='49e94028fb2144d181a78ca9e06c5ce5'. Attempted logging new value 'tmp_trainer/runs/Jul27_10-02-10_kccheng1988'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## 6. Kickstart training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1540\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1541\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1542\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1544\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/transformers/trainer.py:1752\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1749\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step\n\u001b[1;32m   1750\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m-> 1752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallback_handler\u001b[39m.\u001b[39;49mon_train_begin(args, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontrol)\n\u001b[1;32m   1754\u001b[0m \u001b[39m# Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\u001b[39;00m\n\u001b[1;32m   1755\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args\u001b[39m.\u001b[39mignore_data_skip:\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/transformers/trainer_callback.py:353\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_begin\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_begin\u001b[39m(\u001b[39mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[1;32m    352\u001b[0m     control\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_event(\u001b[39m\"\u001b[39;49m\u001b[39mon_train_begin\u001b[39;49m\u001b[39m\"\u001b[39;49m, args, state, control)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/transformers/trainer_callback.py:397\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_event\u001b[39m(\u001b[39mself\u001b[39m, event, args, state, control, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    396\u001b[0m     \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m--> 397\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(callback, event)(\n\u001b[1;32m    398\u001b[0m             args,\n\u001b[1;32m    399\u001b[0m             state,\n\u001b[1;32m    400\u001b[0m             control,\n\u001b[1;32m    401\u001b[0m             model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    402\u001b[0m             tokenizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer,\n\u001b[1;32m    403\u001b[0m             optimizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer,\n\u001b[1;32m    404\u001b[0m             lr_scheduler\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlr_scheduler,\n\u001b[1;32m    405\u001b[0m             train_dataloader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataloader,\n\u001b[1;32m    406\u001b[0m             eval_dataloader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_dataloader,\n\u001b[1;32m    407\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    408\u001b[0m         )\n\u001b[1;32m    409\u001b[0m         \u001b[39m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/transformers/integrations.py:1017\u001b[0m, in \u001b[0;36mMLflowCallback.on_train_begin\u001b[0;34m(self, args, state, control, model, **kwargs)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_begin\u001b[39m(\u001b[39mself\u001b[39m, args, state, control, model\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1016\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialized:\n\u001b[0;32m-> 1017\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(args, state, model)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/transformers/integrations.py:1008\u001b[0m, in \u001b[0;36mMLflowCallback.setup\u001b[0;34m(self, args, state, model)\u001b[0m\n\u001b[1;32m   1006\u001b[0m combined_dict_items \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(combined_dict\u001b[39m.\u001b[39mitems())\n\u001b[1;32m   1007\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(combined_dict_items), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_MAX_PARAMS_TAGS_PER_BATCH):\n\u001b[0;32m-> 1008\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ml_flow\u001b[39m.\u001b[39;49mlog_params(\u001b[39mdict\u001b[39;49m(combined_dict_items[i : i \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_MAX_PARAMS_TAGS_PER_BATCH]))\n\u001b[1;32m   1009\u001b[0m mlflow_tags \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mMLFLOW_TAGS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1010\u001b[0m \u001b[39mif\u001b[39;00m mlflow_tags:\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/mlflow/tracking/fluent.py:750\u001b[0m, in \u001b[0;36mlog_params\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    748\u001b[0m run_id \u001b[39m=\u001b[39m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[1;32m    749\u001b[0m params_arr \u001b[39m=\u001b[39m [Param(key, \u001b[39mstr\u001b[39m(value)) \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mitems()]\n\u001b[0;32m--> 750\u001b[0m MlflowClient()\u001b[39m.\u001b[39;49mlog_batch(run_id\u001b[39m=\u001b[39;49mrun_id, metrics\u001b[39m=\u001b[39;49m[], params\u001b[39m=\u001b[39;49mparams_arr, tags\u001b[39m=\u001b[39;49m[])\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/mlflow/tracking/client.py:1037\u001b[0m, in \u001b[0;36mMlflowClient.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_batch\u001b[39m(\n\u001b[1;32m    979\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    980\u001b[0m     run_id: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    983\u001b[0m     tags: Sequence[RunTag] \u001b[39m=\u001b[39m (),\n\u001b[1;32m    984\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    985\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[39m    Log multiple metrics, params, and/or tags.\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39m        status: FINISHED\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1037\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mlog_batch(run_id, metrics, params, tags)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:391\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m    388\u001b[0m     metrics_batch \u001b[39m=\u001b[39m metrics[:metrics_batch_size]\n\u001b[1;32m    389\u001b[0m     metrics \u001b[39m=\u001b[39m metrics[metrics_batch_size:]\n\u001b[0;32m--> 391\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mlog_batch(\n\u001b[1;32m    392\u001b[0m         run_id\u001b[39m=\u001b[39;49mrun_id, metrics\u001b[39m=\u001b[39;49mmetrics_batch, params\u001b[39m=\u001b[39;49mparams_batch, tags\u001b[39m=\u001b[39;49mtags_batch\n\u001b[1;32m    393\u001b[0m     )\n\u001b[1;32m    395\u001b[0m \u001b[39mfor\u001b[39;00m metrics_batch \u001b[39min\u001b[39;00m chunk_list(metrics, chunk_size\u001b[39m=\u001b[39mMAX_METRICS_PER_BATCH):\n\u001b[1;32m    396\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstore\u001b[39m.\u001b[39mlog_batch(run_id\u001b[39m=\u001b[39mrun_id, metrics\u001b[39m=\u001b[39mmetrics_batch, params\u001b[39m=\u001b[39m[], tags\u001b[39m=\u001b[39m[])\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:1056\u001b[0m, in \u001b[0;36mFileStore.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_run_tag(run_info, tag)\n\u001b[1;32m   1055\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(e, INTERNAL_ERROR)\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='logging_dir' was already logged with value='tmp_trainer/runs/Jul27_09-58-44_kccheng1988' for run ID='49e94028fb2144d181a78ca9e06c5ce5'. Attempted logging new value 'tmp_trainer/runs/Jul27_10-02-10_kccheng1988'."
     ]
    }
   ],
   "source": [
    "## 6. Kickstart training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
